{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Different layers in Neural Network 1D and 2D emulated data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/findingfoot/ML_practice-codes/blob/master/Different_layers_in_Neural_Network_1D_and_2D_emulated_data.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "-V8uhfkSBDhk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Info:\n",
        "    We will be dealing with different kinds of layers in Neural Networks\n",
        "    \n",
        "    1. Convolution Layer\n",
        "    2. Activation Layer\n",
        "    3. Max Pool layer\n",
        "    4. Full connected layer\n",
        "    \n",
        "    Kind of datasets used:\n",
        "        1. 1D data emulating row wise data\n",
        "        2. 2D data emulating images"
      ]
    },
    {
      "metadata": {
        "id": "GuAOVwqLBDhl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import csv\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "05HR4BnyBDho",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ops.reset_default_graph()\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "\n",
        "#conv layer stuff\n",
        "size_of_data = 25\n",
        "conv_filter_size = 5\n",
        "maxpool_size = 5\n",
        "stride = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxuqtpyoBDhr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reproducibility\n",
        "\n",
        "seed = 23\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9QeOYFnNBDhu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Begin with 1D data\n",
        "\n",
        "data_1d = np.random.normal(size=size_of_data)\n",
        "\n",
        "#now create a placeholder \n",
        "x_input_1d = tf.placeholder(dtype=tf.float32, shape=[size_of_data])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sxvnnqrWBDhx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create the convolution\n",
        "\n",
        "def conv_layer_1d(input_1d, my_filter, stride):\n",
        "    input_2d = tf.expand_dims(input_1d, 0)\n",
        "    input_3d = tf.expand_dims(input_2d, 0)\n",
        "    input_4d = tf.expand_dims(input_3d, 3)\n",
        "    \n",
        "    conv_output = tf.nn.conv2d(input_4d, filter = my_filter, strides = [1,1,stride,1], padding = 'VALID')\n",
        "    \n",
        "    #removing the added dimension\n",
        "    \n",
        "    conv_output_1d = tf.squeeze(conv_output)\n",
        "    return(conv_output_1d)\n",
        "\n",
        "my_filter = tf.Variable(tf.random_normal(shape = [1,conv_filter_size,1,1]))\n",
        "\n",
        "my_convolution_output = conv_layer_1d(x_input_1d,my_filter, stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XPCqUSNEBDhz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#activation function\n",
        "def activation(input_1d):\n",
        "    return(tf.nn.relu(input_1d))\n",
        "\n",
        "#creating activation layer\n",
        "my_activation_output = activation(my_convolution_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8IH2FGNaBDh4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#max pooling layer\n",
        "\n",
        "def max_pool(input_1d, width, stride):\n",
        "    input_2d = tf.expand_dims(input_1d, 0)\n",
        "    input_3d = tf.expand_dims(input_2d, 0)\n",
        "    input_4d = tf.expand_dims(input_3d, 3)\n",
        "    \n",
        "    #specify the window size\n",
        "    \n",
        "    pool_output = tf.nn.max_pool(input_4d, \n",
        "                                 ksize=[1,1,width,1], \n",
        "                                 strides= [1,1,stride,1],\n",
        "                                padding = \"VALID\")\n",
        "    \n",
        "    #removing extra dimension\n",
        "    pool_output_1d = tf.squeeze(pool_output)\n",
        "    \n",
        "    return(pool_output_1d)\n",
        "\n",
        "my_max_pool_output = max_pool(my_activation_output, width = maxpool_size, stride = stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6gZnW94BDh6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99ecead2-e265-4cc5-f0fa-b4228b800194"
      },
      "cell_type": "code",
      "source": [
        "#fully connected layer\n",
        "\n",
        "def fully_connected(input_layer, num_outputs):\n",
        "    #shape of multiplication weight matrix\n",
        "    print('shape of input layer',(num_outputs))\n",
        "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer), [num_outputs]]))\n",
        "    \n",
        "    #initialize weight\n",
        "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
        "    \n",
        "    #initialize the bias\n",
        "    \n",
        "    bias = tf.random_normal(shape=[num_outputs])\n",
        "    \n",
        "    #converting 1d array into 2d array\n",
        "    input_layer_2d = tf.expand_dims(input_layer, 0)\n",
        "    \n",
        "    #do the matrix multiplication and add bias\n",
        "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
        "    \n",
        "    #squeeze out the extra dimension\n",
        "    \n",
        "    full_output_1d = tf.squeeze(full_output)\n",
        "    \n",
        "    return (full_output_1d)\n",
        "\n",
        "my_full_output = fully_connected(my_max_pool_output, 5)\n",
        "    "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of input layer 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bYK7h7JvBDiA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "48bd4489-0646-47a9-98ca-6bab8c54b671"
      },
      "cell_type": "code",
      "source": [
        "#lets run the graph and see\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "feed_dict = {x_input_1d: data_1d}\n",
        "\n",
        "print('++++++++++++++++ Running 1D data ++++++++++++++++++++++ \\n')\n",
        "\n",
        "print('Input = array of length %d ' %(x_input_1d.shape.as_list()[0]))\n",
        "print('convolution with filter, length = %d, stride size = %d, results in an array of length %d : \\n' \n",
        "      % (conv_filter_size, stride, my_convolution_output.shape.as_list()[0]))\n",
        "\n",
        "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
        "\n",
        "\n",
        "print('\\n\\n+++++++++++ Activation Block +++++++++++++++++')\n",
        "\n",
        "print('\\n Input = above array of length %d' % (my_convolution_output.shape.as_list()[0]))\n",
        "print('\\n Relu activation function returns an array of length %d' %(my_activation_output.shape.as_list()[0]))\n",
        "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
        "\n",
        "\n",
        "print('++++++++++++++++++++++ Max Pool layer +++++++++++++++++++')\n",
        "print('\\n Input = above array of length %d' % (my_activation_output.shape.as_list()[0]))\n",
        "print('Max Pool, window length = %d, stride size = %d, results in an array of length %d : \\n' \n",
        "      % (maxpool_size,stride, my_max_pool_output.shape.as_list()[0]))\n",
        "print(sess.run(my_max_pool_output, feed_dict=feed_dict))\n",
        "\n",
        "\n",
        "print('\\n++++++++++++++++++++++ Fully Connected Layer ++++++++++++++++++')\n",
        "print('\\n Input = above array of length %d' % (my_max_pool_output.shape.as_list()[0]))\n",
        "print('Fully connected layer on all 4 rows with %d outputs:' % \n",
        "      (my_full_output.shape.as_list()[0]))\n",
        "print(sess.run(my_full_output, feed_dict=feed_dict))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "++++++++++++++++ Running 1D data ++++++++++++++++++++++ \n",
            "\n",
            "Input = array of length 25 \n",
            "convolution with filter, length = 5, stride size = 1, results in an array of length 21 : \n",
            "\n",
            "[-0.08767419 -2.3798776   0.45607725  1.4182255   2.0363877   2.753027\n",
            " -3.5175762  -0.99021906 -2.4224021   1.4362352  -1.3924831   1.9778298\n",
            "  2.9213955   0.40812322 -4.9096665   0.9910472   2.7992413   2.7859051\n",
            " -3.77736    -1.9265695  -1.6774355 ]\n",
            "\n",
            "\n",
            "+++++++++++ Activation Block +++++++++++++++++\n",
            "\n",
            " Input = above array of length 21\n",
            "\n",
            " Relu activation function returns an array of length 21\n",
            "[0.         0.         0.45607725 1.4182255  2.0363877  2.753027\n",
            " 0.         0.         0.         1.4362352  0.         1.9778298\n",
            " 2.9213955  0.40812322 0.         0.9910472  2.7992413  2.7859051\n",
            " 0.         0.         0.        ]\n",
            "++++++++++++++++++++++ Max Pool layer +++++++++++++++++++\n",
            "\n",
            " Input = above array of length 21\n",
            "Max Pool, window length = 5, stride size = 1, results in an array of length 17 : \n",
            "\n",
            "[2.0363877 2.753027  2.753027  2.753027  2.753027  2.753027  1.4362352\n",
            " 1.9778298 2.9213955 2.9213955 2.9213955 2.9213955 2.9213955 2.7992413\n",
            " 2.7992413 2.7992413 2.7992413]\n",
            "\n",
            "++++++++++++++++++++++ Fully Connected Layer ++++++++++++++++++\n",
            "\n",
            " Input = above array of length 17\n",
            "Fully connected layer on all 4 rows with 5 outputs:\n",
            "[-0.21755943  0.56317854  0.40441895 -1.8130038  -0.26462418]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gg40SoY_BDiE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Lets deal with 2D data\n",
        "\n",
        "ops.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "\n",
        "#parameters for the run\n",
        "\n",
        "row_size = 10\n",
        "col_size = 10\n",
        "conv_size = 2\n",
        "conv_stride_size = 2\n",
        "maxpool_size = 2\n",
        "maxpool_stride_size = 1\n",
        "\n",
        "seed = 14\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oMCF1FrvBDiH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_size = [row_size, col_size]\n",
        "data_2d  = np.random.normal(size = data_size)\n",
        "\n",
        "x_input_2d = tf.placeholder(dtype = tf.float32, shape=data_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M_ZEsMSaBDiL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#convolution layer for 2d\n",
        "\n",
        "def conv_layer_2d(input_2d, my_filter, stride_size):\n",
        "    input_3d = tf.expand_dims(input_2d, 0)\n",
        "    input_4d = tf.expand_dims(input_3d, 3)\n",
        "    \n",
        "    convolution_output = tf.nn.conv2d(input_4d, filter = my_filter,\n",
        "                                      strides = [1, stride_size, stride_size, 1]\n",
        "                                     , padding = \"VALID\")\n",
        "    \n",
        "    #removing extra dimenstions\n",
        "    conv_output_2d = tf.squeeze(convolution_output)\n",
        "    return(conv_output_2d)\n",
        "\n",
        "my_filter = tf.random_normal(shape = [conv_size,conv_size,1,1], dtype = tf.float32)\n",
        "my_convolution_output = conv_layer_2d(x_input_2d, my_filter=my_filter, stride_size=conv_stride_size)\n",
        "    \n",
        "    \n",
        "#Activation function\n",
        "\n",
        "def activation(input_1d):\n",
        "    return(tf.nn.relu(input_1d))\n",
        "\n",
        "my_activation_output = activation(my_convolution_output)\n",
        "\n",
        "#max pool layer\n",
        "\n",
        "def max_pool(input_2d, width, height, stride):\n",
        "    input_3d = tf.expand_dims(input_2d, 0)\n",
        "    input_4d = tf.expand_dims(input_3d, 3)\n",
        "    \n",
        "    pool_output = tf.nn.max_pool(input_4d, ksize=[1, height, width, 1],\n",
        "                                strides = [1, stride, stride, 1],\n",
        "                                padding = \"VALID\")\n",
        "    \n",
        "    pool_output_2d = tf.squeeze(pool_output)\n",
        "    return(pool_output_2d)\n",
        "\n",
        "my_maxpool_output = max_pool(my_activation_output, width=maxpool_size, height = maxpool_size,\n",
        "                            stride = maxpool_stride_size)\n",
        "\n",
        "\n",
        "#fully connected layer\n",
        "\n",
        "def fully_connected(input_layer, num_outputs):\n",
        "    flat_input = tf.reshape(input_layer, [-1])\n",
        "    \n",
        "    weight_shape = tf.squeeze(tf.stack([tf.shape(flat_input),[num_outputs]]))\n",
        "    \n",
        "    weight = tf.random_normal(weight_shape, stddev = 0.1)\n",
        "    \n",
        "    bias = tf.random_normal(shape = [num_outputs])\n",
        "    \n",
        "    input_2d = tf.expand_dims(flat_input, 0)\n",
        "    \n",
        "    full_output = tf.add(tf.matmul(input_2d, weight), bias)\n",
        "    \n",
        "    full_output_2d = tf.squeeze(full_output)\n",
        "\n",
        "    return(full_output_2d)\n",
        "\n",
        "my_full_output = fully_connected(my_maxpool_output, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LUThBzx6BDiO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 508
        },
        "outputId": "03e63256-446d-4712-f913-7e17eed1102b"
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "feed_dict = {x_input_2d: data_2d}\n",
        "\n",
        "print('>>>> 2D Data <<<<')\n",
        "\n",
        "# Convolution Output\n",
        "print('Input = %s array' % (x_input_2d.shape.as_list()))\n",
        "print('%s Convolution, stride size = [%d, %d] , results in the %s array' % \n",
        "      (my_filter.get_shape().as_list()[:2],conv_stride_size,conv_stride_size,my_convolution_output.shape.as_list()))\n",
        "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
        "\n",
        "# Activation Output\n",
        "print('\\nInput = the above %s array' % (my_convolution_output.shape.as_list()))\n",
        "print('ReLU element wise returns the %s array' % (my_activation_output.shape.as_list()))\n",
        "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
        "\n",
        "# Max Pool Output\n",
        "print('\\nInput = the above %s array' % (my_activation_output.shape.as_list()))\n",
        "print('MaxPool, stride size = [%d, %d], results in %s array' % \n",
        "      (maxpool_stride_size,maxpool_stride_size,my_maxpool_output.shape.as_list()))\n",
        "print(sess.run(my_maxpool_output, feed_dict=feed_dict))\n",
        "\n",
        "# Fully Connected Output\n",
        "print('\\nInput = the above %s array' % (my_maxpool_output.shape.as_list()))\n",
        "print('Fully connected layer on all %d rows results in %s outputs:' % \n",
        "      (my_maxpool_output.shape.as_list()[0],my_full_output.shape.as_list()[0]))\n",
        "print(sess.run(my_full_output, feed_dict=feed_dict))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>>> 2D Data <<<<\n",
            "Input = [10, 10] array\n",
            "[2, 2] Convolution, stride size = [2, 2] , results in the [5, 5] array\n",
            "[[-2.6543946  -1.826481    2.4554284   3.346291   -1.7156737 ]\n",
            " [-1.9840114  -1.4294717   1.5124216  -3.6152885  -0.990766  ]\n",
            " [-2.912898    1.1083796  -3.3490636   0.22011638 -0.25112176]\n",
            " [ 3.4821644   3.5253954  -4.0970163   1.7628901  -0.07008743]\n",
            " [ 2.5144246   1.7911873   2.1380415  -0.7509017   2.091725  ]]\n",
            "\n",
            "Input = the above [5, 5] array\n",
            "ReLU element wise returns the [5, 5] array\n",
            "[[0.         0.27592117 0.131613   0.07465228 0.        ]\n",
            " [0.         0.         0.93434703 0.         0.        ]\n",
            " [0.         1.0157608  0.09662145 0.         1.3311785 ]\n",
            " [2.8225572  0.6472102  0.         0.88419056 1.6294262 ]\n",
            " [0.6589929  1.0502551  1.5168029  0.         0.7599966 ]]\n",
            "\n",
            "Input = the above [5, 5] array\n",
            "MaxPool, stride size = [1, 1], results in [4, 4] array\n",
            "[[0.3871706 2.3803105 3.1918988 3.1918988]\n",
            " [0.3871706 0.3871706 2.4946017 2.4946017]\n",
            " [1.0912018 1.0912018 2.4946017 2.4946017]\n",
            " [1.3007553 1.0912018 1.0839756 1.0839756]]\n",
            "\n",
            "Input = the above [4, 4] array\n",
            "Fully connected layer on all 4 rows results in 5 outputs:\n",
            "[-2.3949065  -1.6428515   0.11036733 -1.1218873   1.8806196 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_-HurlTlBDiR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}