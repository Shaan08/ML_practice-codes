{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Different layers in Neural Network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/findingfoot/ML_practice-codes/blob/master/Different_layers_in_Neural_Network.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "6eZ-YPrObWP-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Info:\n",
        "    We will be dealing with different kinds of layers in Neural Networks\n",
        "    \n",
        "    1. Convolution Layer\n",
        "    2. Activation Layer\n",
        "    3. Max Pool layer\n",
        "    4. Full connected layer\n",
        "    \n",
        "    Kind of datasets used:\n",
        "        1. 1D data emulating row wise data\n",
        "        2. 2D data emulating images"
      ]
    },
    {
      "metadata": {
        "id": "pk-yoFFmbWP_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import csv\n",
        "import os\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BlDiBXs0bWQC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ops.reset_default_graph()\n",
        "\n",
        "sess = tf.Session()\n",
        "\n",
        "\n",
        "#conv layer stuff\n",
        "size_of_data = 25\n",
        "conv_filter_size = 5\n",
        "maxpool_size = 5\n",
        "stride = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RdRJSovQbWQF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#reproducibility\n",
        "\n",
        "seed = 23\n",
        "np.random.seed(seed)\n",
        "tf.set_random_seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eYXSHZaWbWQH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Begin with 1D data\n",
        "\n",
        "data_1d = np.random.normal(size=size_of_data)\n",
        "\n",
        "#now create a placeholder \n",
        "x_input_1d = tf.placeholder(dtype=tf.float32, shape=[size_of_data])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kHnQipB3bWQL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#create the convolution\n",
        "\n",
        "def conv_layer_1d(input_1d, my_filter, stride):\n",
        "    input_2d = tf.expand_dims(input_1d, 0)\n",
        "    input_3d = tf.expand_dims(input_2d, 0)\n",
        "    input_4d = tf.expand_dims(input_3d, 3)\n",
        "    \n",
        "    conv_output = tf.nn.conv2d(input_4d, filter = my_filter, strides = [1,1,stride,1], padding = 'VALID')\n",
        "    \n",
        "    #removing the added dimension\n",
        "    \n",
        "    conv_output_1d = tf.squeeze(conv_output)\n",
        "    return(conv_output_1d)\n",
        "\n",
        "my_filter = tf.Variable(tf.random_normal(shape = [1,conv_filter_size,1,1]))\n",
        "\n",
        "my_convolution_output = conv_layer_1d(x_input_1d,my_filter, stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8hvBCFbCbWQS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#activation function\n",
        "def activation(input_1d):\n",
        "    return(tf.nn.relu(input_1d))\n",
        "\n",
        "#creating activation layer\n",
        "my_activation_output = activation(my_convolution_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_AYUTXeDbWQV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#max pooling layer\n",
        "\n",
        "def max_pool(input_1d, width, stride):\n",
        "    input_2d = tf.expand_dims(input_1d, 0)\n",
        "    input_3d = tf.expand_dims(input_2d, 0)\n",
        "    input_4d = tf.expand_dims(input_3d, 3)\n",
        "    \n",
        "    #specify the window size\n",
        "    \n",
        "    pool_output = tf.nn.max_pool(input_4d, \n",
        "                                 ksize=[1,1,width,1], \n",
        "                                 strides= [1,1,stride,1],\n",
        "                                padding = \"VALID\")\n",
        "    \n",
        "    #removing extra dimension\n",
        "    pool_output_1d = tf.squeeze(pool_output)\n",
        "    \n",
        "    return(pool_output_1d)\n",
        "\n",
        "my_max_pool_output = max_pool(my_activation_output, width = maxpool_size, stride = stride)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nz3aMZefbWQY",
        "colab_type": "code",
        "colab": {},
        "outputId": "51260cc9-ac9e-49d3-91dd-dd9c2126b287"
      },
      "cell_type": "code",
      "source": [
        "#fully connected layer\n",
        "\n",
        "def fully_connected(input_layer, num_outputs):\n",
        "    #shape of multiplication weight matrix\n",
        "    print('shape of input layer',(num_outputs))\n",
        "    weight_shape = tf.squeeze(tf.stack([tf.shape(input_layer), [num_outputs]]))\n",
        "    \n",
        "    #initialize weight\n",
        "    weight = tf.random_normal(weight_shape, stddev=0.1)\n",
        "    \n",
        "    #initialize the bias\n",
        "    \n",
        "    bias = tf.random_normal(shape=[num_outputs])\n",
        "    \n",
        "    #converting 1d array into 2d array\n",
        "    input_layer_2d = tf.expand_dims(input_layer, 0)\n",
        "    \n",
        "    #do the matrix multiplication and add bias\n",
        "    full_output = tf.add(tf.matmul(input_layer_2d, weight), bias)\n",
        "    \n",
        "    #squeeze out the extra dimension\n",
        "    \n",
        "    full_output_1d = tf.squeeze(full_output)\n",
        "    \n",
        "    return (full_output_1d)\n",
        "\n",
        "my_full_output = fully_connected(my_max_pool_output, 5)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of input layer 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AjSoG9KrbWQe",
        "colab_type": "code",
        "colab": {},
        "outputId": "f8788895-c336-4be1-f29a-1f025e9b9c06"
      },
      "cell_type": "code",
      "source": [
        "#lets run the graph and see\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)\n",
        "\n",
        "feed_dict = {x_input_1d: data_1d}\n",
        "\n",
        "print('++++++++++++++++ Running 1D data ++++++++++++++++++++++ \\n')\n",
        "\n",
        "print('Input = array of length %d ' %(x_input_1d.shape.as_list()[0]))\n",
        "print('convolution with filter, length = %d, stride size = %d, results in an array of length %d : \\n' \n",
        "      % (conv_filter_size, stride, my_convolution_output.shape.as_list()[0]))\n",
        "\n",
        "print(sess.run(my_convolution_output, feed_dict=feed_dict))\n",
        "\n",
        "\n",
        "print('\\n\\n+++++++++++ Activation Block +++++++++++++++++')\n",
        "\n",
        "print('\\n Input = above array of length %d' % (my_convolution_output.shape.as_list()[0]))\n",
        "print('\\n Relu activation function returns an array of length %d' %(my_activation_output.shape.as_list()[0]))\n",
        "print(sess.run(my_activation_output, feed_dict=feed_dict))\n",
        "\n",
        "\n",
        "print('++++++++++++++++++++++ Max Pool layer +++++++++++++++++++')\n",
        "print('\\n Input = above array of length %d' % (my_activation_output.shape.as_list()[0]))\n",
        "print('Max Pool, window length = %d, stride size = %d, results in an array of length %d : \\n' \n",
        "      % (maxpool_size,stride, my_max_pool_output.shape.as_list()[0]))\n",
        "print(sess.run(my_max_pool_output, feed_dict=feed_dict))\n",
        "\n",
        "\n",
        "print('\\n++++++++++++++++++++++ Fully Connected Layer ++++++++++++++++++')\n",
        "print('\\n Input = above array of length %d' % (my_max_pool_output.shape.as_list()[0]))\n",
        "print('Fully connected layer on all 4 rows with %d outputs:' % \n",
        "      (my_full_output.shape.as_list()[0]))\n",
        "print(sess.run(my_full_output, feed_dict=feed_dict))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "++++++++++++++++ Running 1D data ++++++++++++++++++++++ \n",
            "\n",
            "Input = array of length 25 \n",
            "convolution with filter, length = 5, stride size = 1, results in an array of length 21 : \n",
            "\n",
            "[-0.41701764 -2.7259521   1.4663595   1.9974064   1.0364381   2.8468585\n",
            " -2.5038176  -2.2123046   0.54763734 -0.9993551  -0.12350886  1.67453\n",
            "  2.634409   -0.34433162 -3.4637158   1.6823386   3.9866822   0.10009709\n",
            " -2.3700492  -1.909903   -0.8372239 ]\n",
            "\n",
            "\n",
            "+++++++++++ Activation Block +++++++++++++++++\n",
            "\n",
            " Input = above array of length 21\n",
            "\n",
            " Relu activation function returns an array of length 21\n",
            "[0.         0.         1.4663595  1.9974064  1.0364381  2.8468585\n",
            " 0.         0.         0.54763734 0.         0.         1.67453\n",
            " 2.634409   0.         0.         1.6823386  3.9866822  0.10009709\n",
            " 0.         0.         0.        ]\n",
            "++++++++++++++++++++++ Max Pool layer +++++++++++++++++++\n",
            "\n",
            " Input = above array of length 21\n",
            "Max Pool, window length = 5, stride size = 1, results in an array of length 17 : \n",
            "\n",
            "[1.9974064  2.8468585  2.8468585  2.8468585  2.8468585  2.8468585\n",
            " 0.54763734 1.67453    2.634409   2.634409   2.634409   2.634409\n",
            " 3.9866822  3.9866822  3.9866822  3.9866822  3.9866822 ]\n",
            "\n",
            "++++++++++++++++++++++ Fully Connected Layer ++++++++++++++++++\n",
            "\n",
            " Input = above array of length 17\n",
            "Fully connected layer on all 4 rows with 5 outputs:\n",
            "[-0.75135076 -0.28835434  1.4282612  -0.8433349   2.7874951 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WZx9NWtebWQi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}